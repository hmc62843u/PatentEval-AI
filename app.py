import streamlit as st
import json
import requests
from pathlib import Path
from datetime import datetime, timedelta
import re
from bs4 import BeautifulSoup
import urllib.parse
from ddgs import DDGS
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
import groq

# Configure Groq client
try:
    GROQ_API_KEY = st.secrets["GROQ_API_KEY"]
    client = groq.Client(api_key=GROQ_API_KEY)
    GROQ_MODEL = "qwen/qwen3-32b"
except (KeyError, FileNotFoundError):
    st.error("❌ GROQ_API_KEY not found in Streamlit secrets. Please configure it in the Secrets tab.")
    st.stop()

# Rate limiting functions (from reference)
def init_usage_tracking():
    """Initialize the usage tracking file if it doesn't exist"""
    if not Path("patent_usage_tracker.json").exists():
        with open("patent_usage_tracker.json", "w") as f:
            json.dump({
                "usage_count": 0, 
                "last_reset": datetime.now().isoformat(), 
                "usage_history": [],
                "total_patents_generated": 0
            }, f)

def check_rate_limit():
    """Check if the rate limit has been exceeded (max 3 uses per hour)"""
    try:
        with open("patent_usage_tracker.json", "r") as f:
            data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        init_usage_tracking()
        return True, 0
    
    # Check if we need to reset the counter (new hour)
    last_reset = datetime.fromisoformat(data["last_reset"])
    now = datetime.now()
    
    if now - last_reset >= timedelta(hours=1):
        # Reset the counter
        data["usage_count"] = 0
        data["last_reset"] = now.isoformat()
        data["usage_history"] = []
        
        with open("patent_usage_tracker.json", "w") as f:
            json.dump(data, f)
    
    # Check if limit exceeded
    if data["usage_count"] >= 3:
        return False, data["usage_count"]
    
    return True, data["usage_count"]

def increment_usage(patent_title=""):
    """Increment the usage counter"""
    try:
        with open("patent_usage_tracker.json", "r") as f:
            data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        init_usage_tracking()
        with open("patent_usage_tracker.json", "r") as f:
            data = json.load(f)
    
    # Check if we need to reset the counter (new hour)
    last_reset = datetime.fromisoformat(data["last_reset"])
    now = datetime.now()
    
    if now - last_reset >= timedelta(hours=1):
        # Reset the counter
        data["usage_count"] = 0
        data["last_reset"] = now.isoformat()
        data["usage_history"] = []
    
    # Increment usage
    data["usage_count"] += 1
    data["total_patents_generated"] = data.get("total_patents_generated", 0) + 1
    data["usage_history"].append({
        "timestamp": now.isoformat(),
        "action": "infringement_analysis",
        "patent_title": patent_title
    })
    
    with open("patent_usage_tracker.json", "w") as f:
        json.dump(data, f)
    
    return data["usage_count"], data["total_patents_generated"]

def render_rate_limit_message(current_usage, is_allowed):
    """Render rate limit information"""
    if not is_allowed:
        st.error("""
        ❌ **Rate Limit Exceeded!**
        
        This demo allows **3 infringement analyses per hour** across all users.
        
        Please try again in the next hour or contact for full access.
        """)
        
        try:
            with open("patent_usage_tracker.json", "r") as f:
                data = json.load(f)
            last_reset_time = datetime.fromisoformat(data["last_reset"])
            next_reset_time = last_reset_time + timedelta(hours=1)
            st.info(f"⏰ **Next reset:** {next_reset_time.strftime('%H:%M:%S')}")
        except (FileNotFoundError, json.JSONDecodeError, KeyError):
            st.info("⏰ **Next reset:** In 1 hour")
        
        return False
    else:
        if current_usage >= 2:  # Warning when approaching limit
            st.warning(f"⚠️ **Usage Alert:** {current_usage}/3 analyses used this hour.")
        return True
    
def render_disclaimer():
    """Render a prominent disclaimer banner"""
    st.markdown("""
    <div style="
        background-color: #fff3cd; 
        border: 1px solid #ffeaa7; 
        border-radius: 5px; 
        padding: 16px; 
        margin: 16px 0;
        color: #856404;
    ">
        <h4 style="margin:0; color: #856404;">⚠️ IMPORTANT DISCLAIMER</h4>
        <p style="margin: 8px 0 0 0;">
            <strong>This tool provides automated analysis for informational purposes only and does not constitute legal advice.</strong>
        </p>
        <ul style="margin: 8px 0 0 0; padding-left: 20px;">
            <li>Results are generated by AI and should be verified by qualified patent attorneys</li>
            <li>Infringement determinations require legal expertise and detailed technical analysis</li>
            <li>This analysis does not replace formal legal opinion or freedom-to-operate analysis</li>
            <li>Always consult with qualified legal professionals before taking any legal action</li>
            <li>Patent infringement cases require detailed claim construction and expert analysis</li>
        </ul>
        <p style="margin: 8px 0 0 0; font-size: 0.9em;">
            By using this tool, you acknowledge that the results are preliminary and require professional legal review.
        </p>
    </div>
    """, unsafe_allow_html=True)

class PDFReport(FPDF):
    def header(self):
        # Logo or header content
        self.set_font('Arial', 'B', 16)
        self.cell(0, 10, 'Patent Infringement Analysis Report', 0, 1, 'C')
        self.set_font('Arial', 'I', 10)
        self.cell(0, 10, f'Generated on {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}', 0, 1, 'C')
        self.ln(10)
    
    def footer(self):
        # Page footer
        self.set_y(-15)
        self.set_font('Arial', 'I', 8)
        self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')
    
    def chapter_title(self, title):
        # Chapter title
        self.set_font('Arial', 'B', 14)
        self.set_fill_color(200, 220, 255)
        self.cell(0, 10, title, 0, 1, 'L', 1)
        self.ln(4)
    
    def chapter_body(self, body):
        # Chapter body text
        self.set_font('Arial', '', 10)
        # Replace any problematic characters and encode properly
        if isinstance(body, str):
            body = body.encode('latin-1', 'replace').decode('latin-1')
        self.multi_cell(0, 8, body)
        self.ln()
    
    def risk_indicator(self, risk_level):
        # Add colored risk indicator
        colors = {
            'High': (255, 0, 0),
            'Medium': (255, 165, 0),
            'Low': (0, 128, 0),
            'Error': (128, 128, 128)
        }
        color = colors.get(risk_level, (128, 128, 128))
        
        self.set_fill_color(*color)
        self.set_text_color(255, 255, 255)
        self.set_font('Arial', 'B', 10)
        self.cell(20, 8, risk_level, 0, 0, 'C', 1)
        self.set_text_color(0, 0, 0)
    
    def add_competitor_section(self, competitor_info, risk_analysis, index):
        # Add competitor analysis section
        self.set_font('Arial', 'B', 12)
        self.cell(0, 8, f'{index}. {competitor_info["name"]}', 0, 1)
        
        # Risk level
        self.set_font('Arial', '', 10)
        self.cell(40, 8, 'Risk Level: ', 0, 0)
        self.risk_indicator(risk_analysis.get('risk_level', 'Unknown'))
        self.ln(8)
        
        # URL
        self.cell(0, 8, f'Website: {competitor_info["url"]}', 0, 1)
        self.ln(4)
        
        # Key findings
        if risk_analysis.get('key_findings'):
            self.set_font('Arial', 'B', 10)
            self.cell(0, 8, 'Key Findings:', 0, 1)
            self.set_font('Arial', '', 10)
            findings = risk_analysis['key_findings']
            if isinstance(findings, str):
                findings = findings.encode('latin-1', 'replace').decode('latin-1')
            self.multi_cell(0, 6, findings)
            self.ln(4)
        
        # Overlapping features
        if risk_analysis.get('overlapping_features'):
            self.set_font('Arial', 'B', 10)
            self.cell(0, 8, 'Overlapping Features:', 0, 1)
            self.set_font('Arial', '', 10)
            for feature in risk_analysis['overlapping_features']:
                if isinstance(feature, str):
                    feature = feature.encode('latin-1', 'replace').decode('latin-1')
                self.multi_cell(0, 6, f'• {feature}')
            self.ln(4)
        
        # Recommendations
        if risk_analysis.get('recommendations'):
            self.set_font('Arial', 'B', 10)
            self.cell(0, 8, 'Recommendations:', 0, 1)
            self.set_font('Arial', '', 10)
            for rec in risk_analysis['recommendations']:
                if isinstance(rec, str):
                    rec = rec.encode('latin-1', 'replace').decode('latin-1')
                self.multi_cell(0, 6, f'• {rec}')
        
        self.ln(10)

def create_pdf_report(infringement_results, patent_claims):
    """Create a comprehensive PDF report"""
    pdf = PDFReport()
    pdf.add_page()
    
    # Title page
    pdf.set_font('Arial', 'B', 18)
    pdf.cell(0, 20, 'PATENT INFRINGEMENT ANALYSIS REPORT', 0, 1, 'C')
    pdf.ln(10)

    # DISCLAIMER - Add prominent disclaimer to PDF
    pdf.set_fill_color(255, 243, 205)  # Light yellow background
    pdf.set_text_color(133, 100, 4)    # Dark yellow text
    pdf.set_font('Arial', 'B', 12)
    pdf.multi_cell(0, 8, 'IMPORTANT DISCLAIMER', 1, 'C', True)
    pdf.set_font('Arial', '', 9)
    disclaimer_text = """
    This report provides automated analysis for informational purposes only and does not constitute legal advice. 
    Results are generated by AI and should be verified by qualified patent attorneys. 
    Infringement determinations require legal expertise and detailed technical analysis. 
    This analysis does not replace formal legal opinion or freedom-to-operate analysis.
    """
    pdf.multi_cell(0, 6, disclaimer_text, 1, 'L', True)
    pdf.ln(10)
    pdf.set_text_color(0, 0, 0)  # Reset to black text

    # Executive Summary
    pdf.chapter_title('EXECUTIVE SUMMARY')
    
    summary_text = f"""
    This report provides a comprehensive analysis of potential patent infringement risks across relevant industries.
    
    Analysis Summary:
    • Competitors Scanned: {infringement_results['scanned_competitors']}
    • High Risk Findings: {infringement_results['high_risk_findings']}
    • Overall Risk Level: {infringement_results['overall_risk_level']}
    • Primary Industry: {infringement_results.get('primary_industry', 'N/A')}
    
    The analysis was conducted using AI-powered industry detection and competitor website scanning to identify potential infringement of the provided patent claims.
    """
    pdf.chapter_body(summary_text)
    
    # Industry Analysis
    pdf.chapter_title('INDUSTRY ANALYSIS')
    industries_text = "Detected Industries and Confidence Levels:\n\n"
    for industry, confidence in infringement_results.get('detected_industries', {}).items():
        industries_text += f"• {industry}: {confidence}% confidence\n"
    pdf.chapter_body(industries_text)
    
    # Patent Claims Overview
    pdf.chapter_title('PATENT CLAIMS OVERVIEW')
    claims_preview = patent_claims[:1000] + "..." if len(patent_claims) > 1000 else patent_claims
    if isinstance(claims_preview, str):
        claims_preview = claims_preview.encode('latin-1', 'replace').decode('latin-1')
    pdf.chapter_body(claims_preview)
    
    # Detailed Competitor Analysis
    pdf.chapter_title('DETAILED COMPETITOR ANALYSIS')
    
    for i, result in enumerate(infringement_results['detailed_results'], 1):
        pdf.add_competitor_section(result['competitor_info'], result['risk_analysis'], i)
        
        # Add page break if needed
        if i % 2 == 0 and i < len(infringement_results['detailed_results']):
            pdf.add_page()
    
    # Recommendations and Next Steps
    pdf.add_page()
    pdf.chapter_title('RECOMMENDATIONS AND NEXT STEPS')
    
    recommendations = """
    Based on the infringement analysis, consider the following actions:
    
    1. HIGH RISK FINDINGS:
       • Conduct detailed technical analysis of high-risk competitors
       • Consider legal consultation for potential infringement cases
       • Monitor these competitors for ongoing activities
    
    2. MEDIUM RISK FINDINGS:
       • Continue monitoring for product updates
       • Document evidence of potential infringement
       • Consider sending inquiry letters
    
    3. ALL FINDINGS:
       • Regularly update this analysis as competitors evolve
       • Consider filing continuation patents to strengthen protection
       • Monitor industry trends for new entrants
    
    4. LEGAL CONSIDERATIONS:
       • Consult with patent attorneys for formal opinion
       • Consider freedom-to-operate analysis
       • Evaluate portfolio strengthening opportunities
    """
    pdf.chapter_body(recommendations)
    
    # Methodology
    pdf.chapter_title('METHODOLOGY & LIMITATIONS')
    methodology = """
    This analysis was conducted using the following methodology:
    
    1. INDUSTRY DETECTION:
       • Multi-tier analysis combining keyword matching, semantic similarity, and AI classification
       • Industry taxonomy covering major technology sectors
       • Confidence-weighted scoring system
    
    2. COMPETITOR DISCOVERY:
       • AI-generated search queries based on patent content
       • Real-time web search using DuckDuckGo
       • Filtering for commercial entities only
    
    3. INFRINGEMENT ANALYSIS:
       • Automated website content scraping and analysis
       • AI-powered feature matching and risk assessment
       • Structured risk categorization (High/Medium/Low)
    
    4. REPORTING:
       • Comprehensive risk assessment
       • Specific feature overlap identification
       • Actionable recommendations
    
    IMPORTANT LIMITATIONS:
    • This is an automated analysis and should be reviewed by qualified legal professionals
    • Website scraping may not capture all relevant product information
    • Analysis is based on publicly available information only
    • Does not include detailed claim construction or legal interpretation
    • Cannot account for patent validity or enforceability issues
    • Results are indicative and require legal verification
    """
    pdf.chapter_body(methodology)
    
    return pdf

def get_pdf_download_link(pdf, filename):
    """Generate a download link for the PDF"""
    pdf_output = pdf.output(dest='S').encode('latin-1')
    b64 = base64.b64encode(pdf_output).decode()
    href = f'<a href="data:application/pdf;base64,{b64}" download="{filename}">📥 Download PDF Report</a>'
    return href

def groq_generate_content(prompt, model=GROQ_MODEL):
    """Generate content using Groq API"""
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=4000
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"Groq API error: {str(e)}")
        return f"Error generating content: {str(e)}"

def extract_text_from_file(uploaded_file):
    """Extract text from uploaded file based on file type"""
    try:
        if uploaded_file.type == "text/plain":
            return uploaded_file.getvalue().decode("utf-8")
        elif uploaded_file.type == "application/pdf":
            # Simple PDF text extraction
            content = uploaded_file.getvalue()
            text = re.sub(r'[^\x00-\x7F]+', ' ', content.decode('latin-1'))
            return text[:5000]  # Limit length
        else:
            return f"File content: {uploaded_file.name}"
    except Exception as e:
        return f"Error reading file: {str(e)}"

def combine_patent_documents(specification_text, claims_text, drawings_text):
    """Combine all patent documents into a comprehensive analysis text"""
    combined_text = f"""
    PATENT SPECIFICATION:
    {specification_text[:3000]}
    
    PATENT CLAIMS:
    {claims_text[:2000]}
    
    DRAWINGS DESCRIPTION:
    {drawings_text[:1000]}
    """
    return combined_text

def keyword_industry_detection(patent_text):
    """Tier 1: Fast keyword-based industry detection"""
    combined_text = patent_text.lower()
    
    industry_taxonomy = {
        'fintech': ['financial', 'banking', 'payment', 'fintech', 'investment', 'lending', 'insurance', 'wealth', 'portfolio', 'transaction', 'digital wallet', 'cryptocurrency'],
        'healthtech': ['healthcare', 'medical', 'patient', 'clinical', 'telemedicine', 'biotech', 'pharmaceutical', 'diagnostic', 'health tech', 'medical device', 'hospital', 'treatment'],
        'edtech': ['education', 'learning', 'course', 'student', 'educational', 'online learning', 'edtech', 'curriculum', 'teaching', 'academic', 'school', 'university'],
        'saas': ['software', 'service', 'cloud', 'subscription', 'enterprise', 'platform', 'api', 'integration', 'dashboard', 'workflow', 'automation', 'business intelligence'],
        'iot': ['internet of things', 'iot', 'connected', 'sensor', 'smart device', 'embedded', 'wireless', 'smart home', 'industrial iot', 'sensor network'],
        'ai_ml': ['artificial intelligence', 'machine learning', 'neural network', 'deep learning', 'ai model', 'algorithm', 'predictive', 'natural language', 'computer vision', 'llm'],
        'ecommerce': ['ecommerce', 'e-commerce', 'online store', 'shopping cart', 'marketplace', 'retail', 'inventory', 'checkout', 'product catalog', 'digital storefront'],
        'cleantech': ['renewable', 'solar', 'wind', 'energy', 'sustainability', 'green tech', 'carbon', 'environmental', 'clean energy', 'climate', 'emissions']
    }
    
    industry_scores = {}
    for industry, keywords in industry_taxonomy.items():
        score = 0
        for keyword in keywords:
            if keyword in combined_text:
                score += len(keyword.split()) * 2
        if score > 0:
            industry_scores[industry] = score
    
    return dict(sorted(industry_scores.items(), key=lambda x: x[1], reverse=True)[:5])

def llm_industry_classifier(patent_text):
    """Tier 2: LLM-based industry classification using Groq"""
    prompt = f"""
    Analyze this patent document to determine the primary industry.
    
    PATENT DOCUMENT:
    {patent_text[:2000]}
    
    Classify into ONE primary industry from this list:
    - fintech (financial technology, banking, payments)
    - healthtech (healthcare, medical technology)
    - edtech (education technology)
    - saas (software as a service, enterprise software)
    - iot (internet of things, connected devices)
    - ai_ml (artificial intelligence, machine learning)
    - ecommerce (online retail, marketplaces)
    - cleantech (renewable energy, sustainability)
    - other (if none of the above fit well)
    
    Respond in this exact JSON format:
    {{
        "primary_industry": "industry_name",
        "confidence": "High/Medium/Low",
        "reasoning": "brief explanation",
        "alternative_industries": ["industry1", "industry2"]
    }}
    """
    
    try:
        response = groq_generate_content(prompt)
        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        if json_match:
            return json.loads(json_match.group())
        else:
            return json.loads(response)
    except Exception as e:
        return {
            "primary_industry": "other",
            "confidence": "Low", 
            "reasoning": f"LLM analysis failed: {str(e)}",
            "alternative_industries": []
        }

def semantic_similarity_analysis(patent_text):
    """Tier 3: Semantic similarity analysis using TF-IDF"""
    try:
        # Industry domain descriptions
        industry_domains = {
            "fintech": "financial technology digital payments banking investment cryptocurrency blockchain fintech insurance wealth management",
            "healthtech": "healthcare medical technology patient care telemedicine biotech pharmaceuticals medical devices diagnostics treatment clinical",
            "edtech": "education learning educational technology online courses digital learning students teachers academic curriculum school university",
            "saas": "software as a service cloud computing enterprise business platform subscription api integration workflow automation",
            "iot": "internet of things connected devices sensors smart home industrial iot wireless embedded systems sensor networks",
            "ai_ml": "artificial intelligence machine learning neural networks deep learning algorithms predictive analytics natural language processing computer vision",
            "ecommerce": "ecommerce online shopping retail marketplace digital storefront inventory management checkout payment gateway",
            "cleantech": "renewable energy sustainability green technology environmental solar wind power carbon emissions clean energy climate"
        }
        
        # Calculate similarities using TF-IDF
        similarities = {}
        vectorizer = TfidfVectorizer()
        
        # Create document corpus
        documents = [patent_text[:2000]] + list(industry_domains.values())
        tfidf_matrix = vectorizer.fit_transform(documents)
        
        # Calculate cosine similarities between patent text and each industry
        patent_vector = tfidf_matrix[0]
        for i, (industry, description) in enumerate(industry_domains.items(), 1):
            industry_vector = tfidf_matrix[i]
            similarity = cosine_similarity(patent_vector, industry_vector)[0][0]
            similarities[industry] = similarity
        
        return dict(sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:5])
        
    except Exception as e:
        st.warning(f"Semantic analysis failed: {str(e)}")
        return {}

def consolidate_industries(keyword_results, llm_results, semantic_results):
    """Consolidate results from all three tiers with weighted scoring"""
    consolidated = {}
    
    weights = {
        'llm': 0.5,
        'semantic': 0.3, 
        'keyword': 0.2
    }
    
    # Process LLM results
    if llm_results.get('primary_industry') and llm_results.get('primary_industry') != 'other':
        industry = llm_results['primary_industry']
        confidence_weight = {'High': 1.0, 'Medium': 0.7, 'Low': 0.4}.get(llm_results.get('confidence', 'Medium'), 0.5)
        consolidated[industry] = weights['llm'] * confidence_weight
    
    # Add LLM alternative industries
    for alt_industry in llm_results.get('alternative_industries', [])[:2]:
        if alt_industry in consolidated:
            consolidated[alt_industry] += weights['llm'] * 0.3
        else:
            consolidated[alt_industry] = weights['llm'] * 0.3
    
    # Process semantic results
    for industry, score in semantic_results.items():
        if industry in consolidated:
            consolidated[industry] += weights['semantic'] * score
        else:
            consolidated[industry] = weights['semantic'] * score
    
    # Process keyword results
    max_keyword_score = max(keyword_results.values()) if keyword_results else 1
    for industry, score in keyword_results.items():
        normalized_score = score / max_keyword_score if max_keyword_score > 0 else 0
        if industry in consolidated:
            consolidated[industry] += weights['keyword'] * normalized_score
        else:
            consolidated[industry] = weights['keyword'] * normalized_score
    
    # Filter and return top industries
    final_industries = dict(sorted(consolidated.items(), key=lambda x: x[1], reverse=True)[:3])
    
    # Convert to percentage confidence
    total = sum(final_industries.values()) if final_industries else 1
    return {industry: round(score/total * 100, 1) for industry, score in final_industries.items()}

def robust_industry_detection(patent_text):
    """Main tiered industry detection function for patent documents"""
    st.info("🔍 Analyzing patent industry context...")
    
    # Tier 1: Fast keyword analysis
    with st.spinner("Tier 1: Keyword analysis..."):
        keyword_industries = keyword_industry_detection(patent_text)
    
    # Tier 2: LLM classification
    with st.spinner("Tier 2: AI classification..."):
        llm_industries = llm_industry_classifier(patent_text)
    
    # Tier 3: Semantic similarity
    with st.spinner("Tier 3: Semantic analysis..."):
        semantic_industries = semantic_similarity_analysis(patent_text)
    
    # Consolidate results
    final_industries = consolidate_industries(keyword_industries, llm_industries, semantic_industries)
    
    # Display analysis results
    with st.expander("📊 Industry Analysis Details", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("**🔤 Keyword Analysis**")
            for industry, score in keyword_industries.items():
                st.write(f"- {industry}: {score}")
        
        with col2:
            st.markdown("**🤖 LLM Classification**")
            st.write(f"Primary: {llm_industries.get('primary_industry', 'N/A')}")
            st.write(f"Confidence: {llm_industries.get('confidence', 'N/A')}")
            st.write(f"Alternatives: {', '.join(llm_industries.get('alternative_industries', []))}")
        
        with col3:
            st.markdown("**🎯 Semantic Similarity**")
            for industry, score in semantic_industries.items():
                st.write(f"- {industry}: {score:.3f}")
    
    return final_industries

def scrape_website_content(url):
    """Scrape and extract meaningful content from a website"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style"]):
            script.decompose()
        
        # Extract meaningful content
        title = soup.find('title')
        title_text = title.get_text().strip() if title else "No title found"
        
        content_parts = []
        
        # Try to get meta description
        meta_desc = soup.find('meta', attrs={'name': 'description'})
        if meta_desc:
            content_parts.append(f"Meta Description: {meta_desc.get('content', '').strip()}")
        
        # Get headings
        for heading in soup.find_all(['h1', 'h2', 'h3']):
            heading_text = heading.get_text().strip()
            if heading_text and len(heading_text) > 10:
                content_parts.append(f"Heading: {heading_text}")
        
        # Get paragraph content
        paragraphs = soup.find_all('p')
        for p in paragraphs[:10]:
            text = p.get_text().strip()
            if len(text) > 50:
                content_parts.append(text)
        
        # Combine all content
        full_content = f"Website Title: {title_text}\n\n" + "\n\n".join(content_parts[:15])
        return full_content[:4000]
    
    except Exception as e:
        return f"Error scraping website: {str(e)}"

def generate_competitor_search_query(patent_text):
    """Use Groq to generate specific competitor search queries based on patent"""
    prompt = f"""
    Based on this patent document, generate 3 specific search queries to find competitor companies that might be working on similar technology.
    
    PATENT DOCUMENT:
    {patent_text[:2000]}
    
    Generate 3 search queries that are:
    1. **Specific to the technology** (not just generic industry terms)
    2. **Include company/product names** if mentioned
    3. **Focus on commercial competitors** (not academic/research)
    4. **Use natural language** that would work in search engines
    
    Return in this exact JSON format:
    {{
        "search_queries": [
            "query 1",
            "query 2", 
            "query 3"
        ],
        "reasoning": "Why these queries are likely to find relevant competitors"
    }}
    """
    
    try:
        response = groq_generate_content(prompt)
        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        if json_match:
            return json.loads(json_match.group())
        else:
            return {
                "search_queries": [
                    "technology companies competitors",
                    "industry leading companies",
                    "innovative tech startups"
                ],
                "reasoning": "Fallback queries generated"
            }
    except Exception as e:
        return {
            "search_queries": ["technology companies competitors"],
            "reasoning": "Error fallback"
        }

def find_relevant_competitors(patent_text, max_competitors=8):
    """Find competitor websites using AI-generated search queries"""
    try:
        # Generate smart search queries
        search_plan = generate_competitor_search_query(patent_text)
        
        st.info(f"🔍 Using smart search: {search_plan.get('reasoning', 'Finding relevant competitors')}")
        
        competitors = []
        seen_urls = set()
        
        with DDGS() as ddgs:
            # Try each search query
            for query in search_plan.get("search_queries", [])[:2]:
                if len(competitors) >= max_competitors:
                    break
                    
                st.write(f"  - Searching: '{query}'")
                search_results = list(ddgs.text(query, max_results=max_competitors))
                
                for result in search_results:
                    if len(competitors) >= max_competitors:
                        break
                        
                    url = result.get("href", "")
                    title = result.get("title", "")
                    
                    # Filter out non-company websites
                    if (url and 
                        any(domain in url for domain in ['.com', '.io', '.co', '.tech', '.ai']) and
                        url not in seen_urls and
                        not any(exclude in url for exclude in ['wikipedia', 'academic', 'research', 'github']) and
                        not any(exclude in title.lower() for exclude in ['wikipedia', 'academic paper', 'research paper'])):
                        
                        competitors.append({
                            "name": title if title else "Unknown Company",
                            "url": url,
                            "description": result.get("body", "")[:200] + "...",
                            "search_query": query
                        })
                        seen_urls.add(url)
        
        return competitors
        
    except Exception as e:
        st.error(f"Error finding competitors: {str(e)}")
        return []

def infringement_risk_analysis(patent_claims, competitor_url):
    """Analyze a specific competitor website for infringement risks using Groq"""
    try:
        # Scrape the competitor site
        site_content = scrape_website_content(competitor_url)
        
        if site_content.startswith("Error"):
            return {
                "competitor_url": competitor_url,
                "risk_level": "Unknown",
                "error": site_content,
                "overlapping_features": [],
                "recommendations": []
            }
        
        # Analyze for infringement risks using Groq
        analysis_prompt = f"""
        PATENT CLAIMS TO ANALYZE:
        {patent_claims}
        
        COMPETITOR WEBSITE CONTENT:
        {site_content}
        
        Analyze for potential patent infringement risks. Focus on:
        
        1. **DIRECT PRODUCT MATCH**: Does the website show products/services that directly implement the claimed invention?
        2. **FEATURE OVERLAP**: Which specific claim elements appear to be implemented in their products?
        3. **TECHNICAL SIMILARITY**: How similar are the technical approaches and implementations?
        4. **COMMERCIAL USE EVIDENCE**: Is there evidence of actual commercial use of similar technology?
        
        Provide your analysis in this exact JSON format:
        {{
            "risk_level": "Low/Medium/High",
            "overlapping_features": ["list of specific overlapping features"],
            "infringement_confidence": "Low/Medium/High",
            "key_findings": "Detailed analysis of potential infringement",
            "recommendations": ["list of recommendations for further action"]
        }}
        
        Be thorough and evidence-based in your assessment.
        """
        
        response = groq_generate_content(prompt)
        
        # Parse the JSON response
        try:
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                analysis_result = json.loads(json_match.group())
            else:
                analysis_result = json.loads(response)
        except json.JSONDecodeError:
            # If JSON parsing fails, create a structured response from text
            analysis_result = {
                "risk_level": "Medium",
                "overlapping_features": ["Unable to parse detailed features"],
                "infringement_confidence": "Medium", 
                "key_findings": response[:500] + "...",
                "recommendations": ["Conduct manual review of this competitor"]
            }
        
        # Add competitor info to result
        analysis_result["competitor_url"] = competitor_url
        analysis_result["scraped_content_preview"] = site_content[:300] + "..."
        
        return analysis_result
        
    except Exception as e:
        return {
            "competitor_url": competitor_url,
            "risk_level": "Error",
            "error": str(e),
            "overlapping_features": [],
            "recommendations": ["Analysis failed - manual review required"]
        }

def industry_wide_infringement_scan(patent_text, patent_claims, max_competitors=5):
    """Main function to scan industry for infringement risks"""
    
    # Use robust industry detection
    detected_industries = robust_industry_detection(patent_text)
    
    if not detected_industries:
        st.error("❌ Could not detect relevant industries for scanning")
        return {
            "error": "Industry detection failed",
            "scanned_competitors": 0,
            "high_risk_findings": 0,
            "detailed_results": []
        }
    
    # Show detected industries
    st.success(f"🎯 Detected Industries: {', '.join(detected_industries.keys())}")
    
    # Use the highest confidence industry as context
    primary_industry = next(iter(detected_industries))
    industry_confidence = detected_industries[primary_industry]
    
    st.info(f"🔍 Scanning {primary_industry} industry (confidence: {industry_confidence}%)...")
    
    # Find competitors using AI-generated search queries
    competitors = find_relevant_competitors(patent_text, max_competitors)
    
    if not competitors:
        st.warning("No relevant competitors found with AI search.")
        return {
            "error": f"No competitors found in {primary_industry} industry",
            "scanned_competitors": 0,
            "high_risk_findings": 0,
            "detailed_results": []
        }
    
    infringement_findings = []
    high_risk_count = 0
    
    # Analyze each competitor
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, competitor in enumerate(competitors):
        status_text.text(f"Analyzing {competitor['name']}... ({i+1}/{len(competitors)})")
        
        risk_analysis = infringement_risk_analysis(patent_claims, competitor["url"])
        infringement_findings.append({
            "competitor_info": competitor,
            "risk_analysis": risk_analysis
        })
        
        if risk_analysis.get("risk_level") == "High":
            high_risk_count += 1
        
        progress_bar.progress((i + 1) / len(competitors))
    
    status_text.text("Analysis complete!")
    
    return {
        "scanned_competitors": len(competitors),
        "high_risk_findings": high_risk_count,
        "detected_industries": detected_industries,
        "primary_industry": primary_industry,
        "detailed_results": infringement_findings,
        "search_method": "AI-Generated Queries",
        "overall_risk_level": "High" if high_risk_count > 0 else "Medium" if len(competitors) > 0 else "Low"
    }

def create_markdown_report(infringement_results, patent_claims):
    """Create a comprehensive markdown report"""
    report = f"""# Patent Infringement Analysis Report

**Generated on:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## ⚠️ Important Disclaimer

This report provides automated analysis for informational purposes only and does not constitute legal advice. 
Results are generated by AI and should be verified by qualified patent attorneys. 
Infringement determinations require legal expertise and detailed technical analysis.

## Executive Summary

- **Competitors Scanned:** {infringement_results['scanned_competitors']}
- **High Risk Findings:** {infringement_results['high_risk_findings']}
- **Overall Risk Level:** {infringement_results['overall_risk_level']}
- **Primary Industry:** {infringement_results.get('primary_industry', 'N/A')}

## Industry Analysis

"""
    
    # Add industry analysis
    for industry, confidence in infringement_results.get('detected_industries', {}).items():
        report += f"- **{industry}**: {confidence}% confidence\n"
    
    report += "\n## Patent Claims Overview\n\n"
    report += f"```\n{patent_claims[:1000]}{'...' if len(patent_claims) > 1000 else ''}\n```\n\n"
    
    report += "## Detailed Competitor Analysis\n\n"
    
    # Add competitor analysis
    for i, result in enumerate(infringement_results['detailed_results'], 1):
        competitor = result['competitor_info']
        analysis = result['risk_analysis']
        
        risk_emoji = {
            "High": "🔴",
            "Medium": "🟡",
            "Low": "🟢",
            "Error": "⚫"
        }.get(analysis.get('risk_level', 'Unknown'), '⚫')
        
        report += f"### {i}. {competitor['name']} {risk_emoji}\n\n"
        report += f"- **Website:** {competitor['url']}\n"
        report += f"- **Risk Level:** {analysis.get('risk_level', 'Unknown')}\n"
        report += f"- **Infringement Confidence:** {analysis.get('infringement_confidence', 'N/A')}\n\n"
        
        if analysis.get('key_findings'):
            report += "#### Key Findings\n\n"
            report += f"{analysis['key_findings']}\n\n"
        
        if analysis.get('overlapping_features'):
            report += "#### Overlapping Features\n\n"
            for feature in analysis['overlapping_features']:
                report += f"- {feature}\n"
            report += "\n"
        
        if analysis.get('recommendations'):
            report += "#### Recommendations\n\n"
            for rec in analysis['recommendations']:
                report += f"- {rec}\n"
            report += "\n"
        
        report += "---\n\n"
    
    # Add methodology and limitations
    report += """## Methodology & Limitations

### Analysis Methodology
1. **Industry Detection**: Multi-tier analysis combining keyword matching, semantic similarity, and AI classification
2. **Competitor Discovery**: AI-generated search queries based on patent content with real-time web search
3. **Infringement Analysis**: Automated website content scraping and AI-powered feature matching
4. **Risk Assessment**: Structured risk categorization (High/Medium/Low) with confidence levels

### Important Limitations
- This is an automated analysis and should be reviewed by qualified legal professionals
- Website scraping may not capture all relevant product information
- Analysis is based on publicly available information only
- Does not include detailed claim construction or legal interpretation
- Cannot account for patent validity or enforceability issues
- Results are indicative and require legal verification

## Next Steps

1. **High Risk Findings**: Conduct detailed technical analysis and consider legal consultation
2. **Medium Risk Findings**: Continue monitoring and document evidence
3. **All Findings**: Regularly update analysis as competitors evolve
4. **Legal Review**: Consult with qualified patent attorneys for formal opinion

---
*Report generated by Patent Infringement Scanner - For informational purposes only*"""
    
    return report

def display_infringement_results(infringement_results, patent_claims):
    """Display infringement analysis results in Streamlit"""
    st.subheader("⚖️ Infringement Risk Analysis Results")
    
    # Show disclaimer again when results are displayed
    st.warning("""
    **Disclaimer Reminder**: These results are AI-generated and for informational purposes only. 
    Always consult with qualified patent attorneys for legal advice and infringement determinations.
    """)
    
    if infringement_results.get('error'):
        st.error(f"Infringement analysis failed: {infringement_results['error']}")
        return
    
    # Summary metrics
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Competitors Scanned", infringement_results['scanned_competitors'])
    with col2:
        st.metric("High Risk Findings", infringement_results['high_risk_findings'])
    with col3:
        st.metric("Overall Risk", infringement_results['overall_risk_level'])
    
    # Industry analysis
    st.markdown("### 🎯 Detected Industries")
    for industry, confidence in infringement_results.get('detected_industries', {}).items():
        st.write(f"- **{industry}**: {confidence}% confidence")
    
    # Detailed results with disclaimer note
    st.markdown("### 📊 Detailed Competitor Analysis")
    st.info("💡 **Note**: Risk levels are AI-estimated. Manual verification by patent experts is required for legal action.")
    
    for i, result in enumerate(infringement_results['detailed_results']):
        competitor = result['competitor_info']
        analysis = result['risk_analysis']
        
        # Color code based on risk level
        risk_color = {
            "High": "red",
            "Medium": "orange", 
            "Low": "green",
            "Error": "gray"
        }.get(analysis.get('risk_level', 'Unknown'), 'gray')
        
        with st.expander(f"🎯 {competitor['name']} - Risk: :{risk_color}[{analysis.get('risk_level', 'Unknown')}]", expanded=i < 2):
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.markdown(f"**Website:** {competitor['url']}")
                st.markdown(f"**Description:** {competitor.get('description', 'N/A')}")
                
                if analysis.get('key_findings'):
                    st.markdown("**Key Findings:**")
                    st.info(analysis['key_findings'])
                
                if analysis.get('overlapping_features'):
                    st.markdown("**Overlapping Features:**")
                    for feature in analysis['overlapping_features']:
                        st.write(f"• {feature}")
            
            with col2:
                st.markdown(f"**Confidence:** {analysis.get('infringement_confidence', 'N/A')}")
                
                if analysis.get('recommendations'):
                    st.markdown("**Recommendations:**")
                    for rec in analysis['recommendations'][:2]:
                        st.write(f"📌 {rec}")
            
            # Visit competitor button
            st.markdown(f"[🌐 Visit Competitor Website]({competitor['url']})")
    
    # Generate and display Markdown download button
    st.markdown("---")
    st.markdown("### 📥 Download Report")
    
    # Create markdown report
    markdown_report = create_markdown_report(infringement_results, patent_claims)
    
    st.download_button(
        label="📥 Download Markdown Report",
        data=markdown_report,
        file_name=f"patent_infringement_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
        mime="text/markdown"
    )

def main():
    st.set_page_config(
        page_title="Patent Infringement Scanner", 
        page_icon="⚖️",
        layout="wide"
    )
    
    # Initialize usage tracking
    init_usage_tracking()
    
    st.title("⚖️ Patent Infringement Scanner")
    
    # Render disclaimer at the top
    render_disclaimer()
    
    # Display usage information
    is_allowed, current_usage = check_rate_limit()
    
    # Sidebar content with usage info
    with st.sidebar:
        st.title("📊 Usage Dashboard")
        
        try:
            with open("patent_usage_tracker.json", "r") as f:
                data = json.load(f)
            total_analyses = data.get("total_patents_generated", 0)
        except:
            total_analyses = 0
            
        st.metric("Analyses This Hour", f"{current_usage}/3")
        st.metric("Total Analyses", total_analyses)
        
        if not is_allowed:
            st.error("❌ Limit Exceeded")
        elif current_usage >= 2:
            st.warning("⚠️ Approaching Limit")
        else:
            st.success("✅ Within Limit")
        
        # Add disclaimer to sidebar
        st.markdown("---")
        st.markdown("### ⚠️ Disclaimer")
        st.sidebar.warning("""
        This tool provides automated analysis only. 
        Always consult with qualified patent attorneys 
        for legal advice and infringement determinations.
        """)
    
    st.markdown("""
    Upload your patent documents to scan for potential infringement risks across the industry.
    This tool uses AI to detect relevant industries and analyze competitor websites for potential patent violations.
    """)
    
    # File upload section
    st.markdown("## 📄 Upload Patent Documents")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### Specification")
        specification_file = st.file_uploader(
            "Upload Patent Specification",
            type=["txt", "pdf"],
            key="specification"
        )
        if specification_file:
            st.success(f"✅ {specification_file.name} uploaded")
    
    with col2:
        st.markdown("### Claims")
        claims_file = st.file_uploader(
            "Upload Patent Claims", 
            type=["txt", "pdf"],
            key="claims"
        )
        if claims_file:
            st.success(f"✅ {claims_file.name} uploaded")
    
    with col3:
        st.markdown("### Drawings/Description")
        drawings_file = st.file_uploader(
            "Upload Patent Drawings Description",
            type=["txt", "pdf"], 
            key="drawings"
        )
        if drawings_file:
            st.success(f"✅ {drawings_file.name} uploaded")
    
    # Analysis options
    st.markdown("## ⚙️ Analysis Options")
    
    col1, col2 = st.columns(2)
    
    with col1:
        max_competitors = st.slider(
            "Maximum Competitors to Analyze",
            min_value=3,
            max_value=10,
            value=5,
            help="Number of competitor websites to scan for infringement risks"
        )
    
    with col2:
        analysis_depth = st.selectbox(
            "Analysis Depth",
            ["Standard", "Comprehensive", "Quick Scan"],
            help="Depth of infringement analysis"
        )
    
    # Start analysis button with rate limiting check
    analyze_button = st.button(
        "🔬 Start Infringement Analysis",
        type="primary",
        disabled=not (specification_file and claims_file and is_allowed)
    )
    
    if not is_allowed:
        render_rate_limit_message(current_usage, is_allowed)
    
    if analyze_button:
        if not (specification_file and claims_file):
            st.error("Please upload both Specification and Claims documents to proceed.")
            return
        
        # Check rate limit again before processing
        is_allowed, current_usage = check_rate_limit()
        if not render_rate_limit_message(current_usage, is_allowed):
            return
        
        # Extract text from files
        with st.spinner("📖 Reading patent documents..."):
            specification_text = extract_text_from_file(specification_file)
            claims_text = extract_text_from_file(claims_file)
            drawings_text = extract_text_from_file(drawings_file) if drawings_file else "No drawings description provided"
        
        # Combine documents for comprehensive analysis
        patent_text = combine_patent_documents(specification_text, claims_text, drawings_text)
        
        # Show document preview
        with st.expander("📄 Patent Documents Preview", expanded=False):
            tab1, tab2, tab3 = st.tabs(["Specification", "Claims", "Drawings"])
            
            with tab1:
                st.text_area("Specification Content", specification_text[:2000], height=200)
            with tab2:
                st.text_area("Claims Content", claims_text[:1500], height=200)
            with tab3:
                st.text_area("Drawings Description", drawings_text[:1000], height=200)
        
        # Perform infringement analysis
        infringement_results = industry_wide_infringement_scan(
            patent_text, 
            claims_text,
            max_competitors
        )
        
        # Increment usage counter after successful analysis
        patent_title = f"Infringement Analysis - {specification_file.name}"
        new_usage_count, total_analyses = increment_usage(patent_title)
        
        # Update sidebar metrics
        st.sidebar.metric("Analyses This Hour", f"{new_usage_count}/3")
        st.sidebar.metric("Total Analyses", total_analyses)
        
        # Display results
        display_infringement_results(infringement_results, claims_text)
    
    # Information section
    st.markdown("---")
    st.markdown("""
    ## 💡 How It Works
    
    1. **Document Analysis**: AI analyzes your patent documents to understand the technology and claims
    2. **Industry Detection**: Identifies relevant industries using keyword, semantic, and LLM analysis
    3. **Competitor Discovery**: Uses AI-generated search queries to find relevant companies
    4. **Infringement Assessment**: Analyzes competitor websites for potential patent violations
    5. **Risk Reporting**: Provides detailed risk assessment and recommendations
    
    ## 🛡️ Features
    
    - **Multi-tier Industry Detection**: Combines keyword, semantic, and AI analysis
    - **Smart Competitor Discovery**: AI-generated search queries for relevant companies
    - **Comprehensive Risk Analysis**: Detailed infringement risk assessment
    - **Actionable Insights**: Specific recommendations for each finding
    - **Markdown Reports**: Download comprehensive analysis in markdown format
    - **Usage Limits**: 3 analyses per hour to ensure service quality
    """)

if __name__ == '__main__':
    main()